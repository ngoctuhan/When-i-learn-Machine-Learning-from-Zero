{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manages the knowledge base used to think.\n",
    "import sys, glob\n",
    "import aiml\n",
    "\n",
    "kernel = aiml.Kernel()\n",
    "kernel.learn(\"corpus/bot-startup.xml\")\n",
    "kernel.respond(\"LOAD AIML B\")\n",
    "\n",
    "while True: print(kernel.respond(str(input(\"> \"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speeding up brain load\n",
    "\n",
    "Despite how powerful the AIML language is, its slow to load when you have a huge number of files operating. In order to overcome that limitation its possible to create a brain file (.brn) that preloads the used responses and ensures they are available on the next execution without having to load the files. Here's the code necessary to create the brain module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AIML module for chatbot.\n",
    "        self.kernel = aiml.Kernel()\n",
    "        #Load brain file if available to speed load times.\n",
    "        if os.path.isfile(directory + \"/bot_brain.brn\"):\n",
    "            self.kernel.bootstrap(brainFile=directory + \"/bot_brain.brn\")\n",
    "        else:\n",
    "            self.kernel.bootstrap(learnFiles=directory + \"/bot-startup.xml\", commands=\"LOAD AIML B\")\n",
    "            self.kernel.saveBrain(directory + \"/bot_brain.brn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
