{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"data_train.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sentence Labels\n",
      "0  Excellent! Our sales are still going up untill...  happy\n",
      "1                            He is an awesome people  happy\n",
      "2  How lucky you are! You?ve just won a valuable ...  happy\n"
     ]
    }
   ],
   "source": [
    "print(data_frame.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data to train :  149\n",
      "Shape of data_frame (149, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data to train : \",len(data_frame))\n",
    "print(\"Shape of data_frame\", data_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Excellent! Our sales are still going up untill...\n",
      "1                              He is an awesome people\n",
      "2    How lucky you are! You?ve just won a valuable ...\n",
      "3                        I have nothing more to desire\n",
      "4                       Nothing could make me happier!\n",
      "Name: Sentence, dtype: object\n",
      "0    happy\n",
      "1    happy\n",
      "2    happy\n",
      "3    happy\n",
      "4    happy\n",
      "Name: Labels, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = data_frame['Sentence']\n",
    "print(data[0:5])\n",
    "labels = data_frame['Labels']\n",
    "print(labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Excellent ! Our sales still going untill ']\n",
      " ['He awesome people ']\n",
      " ['How lucky ! You ? valuable award ']\n",
      " ['I nothing desire ']\n",
      " ['Nothing could make happier ! ']]\n"
     ]
    }
   ],
   "source": [
    "# Stop words\n",
    "stopWords = set(stopwords.words('english'))\n",
    "data_edited = []\n",
    "for sentences in data:\n",
    "    str = \"\"\n",
    "    words = word_tokenize(sentences)\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            str += w + \" \"\n",
    "    data_edited.append(str)\n",
    "data_edited = np.asanyarray(data_edited)\n",
    "data_edited = data_edited.reshape((149, -1))\n",
    "print(data_edited[0: 5][:])\n",
    "data_train = data_edited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "648\n",
      "['10', '10 points', 'a', 'a boring', 'a damp', 'a sombre', 'a work', 'accept', 'accept invitation', 'accepted', 'accepted role', 'alas', 'alas stocks', 'alone', 'always', 'always smile', 'always smiled', 'amuse', 'amuse playing', 'amused', 'amused children', 'amused clown', 'amused learn', 'anything', 'anything right', 'approval', 'art', 'art given', 'award', 'away', 'awesome', 'awesome people', 'baby', 'baby amused', 'back', 'bad', 'bastard', 'become', 'become worthless', 'behind', 'behind back', 'believe', 'believe talking', 'birthday', 'bitch', 'bitter', 'bitter smile', 'book', 'boring', 'boring day', 'bother', 'boy', 'boy lost', 'break', 'breaking', 'broke', 'business', 'ca', 'ca n', 'character', 'cheerful', 'cheerful face', 'cheerful smile', 'cheerless', 'cheerless losts', 'cheerless room', 'chess', 'child', 'child bad', 'child cried', 'child said', 'children', 'chirping', 'chirping crickets', 'christoper', 'christoper man', 'clown', 'clown s', 'comic', 'comic gestures', 'could', 'could make', 'could stoop', 'couple', 'crickets', 'crickets sounded', 'cried', 'cried girlfriend', 'cried joy', 'cried lot', 'cried loudly', 'cry', 'cry behind', 'crying', 'damp', 'damp cheerless', 'david', 'david cheerless', 'day', 'day got', 'dead', 'death', 'decorate', 'decorate room', 'deed', 'dejected', 'dejected result', 'depressed', 'depressed job', 'depressed life', 'desire', 'desperate', 'desperate father', 'desperate future', 'destination', 'detest', 'device', 'die', 'disappointed', 'disappointed team', 'do', 'do know', 'do n', 'do wan', 'doctor', 'dog', 'dog looks', 'don', 'don look', 'done', 'downcast', 'drawings', 'drawings amused', 'drop', 'drop dead', 'ducky', 'ducky scenery', 'evening', 'everyone', 'everyone amused', 'exam', 'exam bad', 'exam n', 'excellent', 'excellent our', 'face', 'failed', 'failed exam', 'failed math', 'family', 'family poor', 'fantastic', 'fantastic day', 'fantastic device', 'father', 'father die', 'feel', 'feel happy', 'feel lonely', 'feels', 'feels lonely', 'fellow', 'finish', 'finish reading', 'finished', 'finished homework', 'forlorn', 'forlorn pass', 'friends', 'friends leave', 'frustrated', 'frustrating', 'frustrating working', 'funny', 'funny drawings', 'future', 'gestures', 'get', 'get back', 'get face', 'get los', 'gets', 'gets nerves', 'girlfriend', 'girlfriend broke', 'given', 'given pleasure', 'gives', 'gives great', 'go', 'go away', 'goal', 'going', 'going untill', 'good', 'good day', 'got', 'got 10', 'got married', 'great', 'great match', 'great pleasure', 'great today', 'happier', 'happily', 'happily accepted', 'happy', 'happy accept', 'happy birthday', 'happy deed', 'happy finish', 'happy husband', 'happy i', 'happy macbook', 'happy score', 'happy see', 'happy today', 'harry', 'harry lonely', 'have', 'have nice', 'he', 'he awesome', 'he cheerful', 'he feel', 'he feels', 'he happy', 'he laughs', 'he looks', 'he never', 'he receives', 'he s', 'he sad', 'he sit', 'he smiled', 'he solitary', 'hears', 'hears death', 'hears tragic', 'heart', 'hell', 'hell going', 'hello', 'help', 'help keep', 'hit', 'hit father', 'homework', 'how', 'how irritating', 'how lucky', 'husband', 'i', 'i ca', 'i detest', 'i failed', 'i feel', 'i finished', 'i got', 'i happy', 'i laughed', 'i m', 'i n', 'i nothing', 'i put', 'i saw', 'i shall', 'i smiled', 'i take', 'i want', 'idiot', 'indeed', 'interesting', 'interesting book', 'interesting novel', 'invitation', 'irritating', 'it', 'it gives', 'it none', 'it really', 'it s', 'jean', 'job', 'joy', 'juliet', 'keep', 'keep baby', 'keep mouth', 'key', 'kill', 'kind', 'kind person', 'know', 'know could', 'know time', 'knucklehead', 'laughed', 'laughed loudly', 'laughs', 'laughs time', 'learn', 'learn s', 'leave', 'leave winter', 'left', 'left life', 'level', 'life', 'like', 'little', 'little boy', 'live', 'live alone', 'living', 'living solitary', 'lonely', 'lonely breaking', 'lonely friends', 'look', 'look great', 'look like', 'look sad', 'looks', 'looks relieved', 'looks sad', 'los', 'lost', 'lost family', 'losts', 'losts key', 'lot', 'lot day', 'lot nerve', 'loudly', 'loudly hit', 'loudly whenever', 'lucky', 'lucky match', 'lucky you', 'm', 'm frustrated', 'm happy', 'm never', 'm really', 'macbook', 'macbook pro', 'mad', 'mad disappointed', 'make', 'make happier', 'man', 'man sombre', 'marriage', 'married', 'match', 'math', 'math test', 'meeting', 'meeting juliet', 'melancholy', 'millions', 'millions people', 'miserable', 'miserable life', 'misses', 'misses exam', 'monday', 'mother', 'mother sad', 'mouth', 'mouth business', 'my', 'my funny', 'n', 'n t', 'na', 'na die', 'nerve', 'nerves', 'never', 'never smiles', 'never trusting', 'news', 'news win', 'nice', 'nice evening', 'none', 'none business', 'nothing', 'nothing could', 'nothing desire', 'novel', 'oh', 'oh decorate', 'oh great', 'our', 'our sales', 'pass', 'pass exam', 'past', 'past pleasure', 'pefect', 'pefect couple', 'people', 'perfectly', 'perfectly well', 'person', 'pity', 'pity pefect', 'playing', 'playing chess', 'pleasure', 'pleasure meeting', 'pleasure millions', 'pleasure welcome', 'pleasures', 'pleasures left', 'points', 'points math', 'points second', 'poor', 'poor fellow', 'pro', 'problem', 'proud', 'put', 're', 're dog', 're talking', 'reading', 'reading interesting', 'really', 'really gets', 'really mad', 'receives', 'receives sad', 'relieved', 'remembering', 'remembering past', 'result', 'right', 'roger', 'roger stabbed', 'role', 'romeo', 'romeo always', 'room', 'room perfectly', 's', 's awesome', 's cheerless', 's comic', 's crying', 's dejected', 's depressed', 's desperate', 's doctor', 's downcast', 's fantastic', 's forlorn', 's frustrating', 's happy', 's living', 's lucky', 's miserable', 's pleasure', 's problem', 'sad', 'sad child', 'sad failed', 'sad hears', 'sad heart', 'sad indeed', 'sad live', 'sad misses', 'sad news', 'sad points', 'sad silent', 'sad tomorrow', 'said', 'said hello', 'sales', 'sales still', 'saw', 'saw face', 'says', 'scenery', 'scenery melancholy', 'score', 'score goal', 'scoundrel', 'screamed', 'screamed happily', 'second', 'second destination', 'see', 'see face', 'shall', 'shall happy', 'she', 'she cheerful', 'she cried', 'she happy', 'she hears', 'she pleasures', 'she s', 'she sad', 'she screamed', 'she smiled', 'she smiles', 'shut', 'shut go', 'silent', 'sit', 'sit sad', 'sky', 'smile', 'smile face', 'smile time', 'smiled', 'smiled approval', 'smiled bitter', 'smiled child', 'smiled meeting', 'smiled thanks', 'smiles', 'smiles jean', 'smiles news', 'solitary', 'solitary kind', 'solitary life', 'solitary walk', 'sombre', 'sombre character', 'sombre sky', 'son', 'son bitch', 'sounded', 'sounded sad', 'speaker', 'stabbed', 'stabbed back', 'still', 'still going', 'stocks', 'stocks become', 'stoop', 'stoop level', 'stupid', 'stupid idiot', 't', 't anything', 't believe', 't bother', 't cry', 't know', 't want', 'take', 'talking', 'talking behind', 'teacher', 'teacher proud', 'team', 'team lost', 'terrible', 'test', 'test s', 'thanks', 'that', 'that i', 'that little', 'that s', 'that terrible', 'the', 'the child', 'the chirping', 'the dog', 'the ducky', 'the mother', 'the teacher', 'these', 'these toys', 'they', 'they always', 'they great', 'think', 'think re', 'tightwad', 'time', 'today', 'today fantastic', 'today feel', 'today good', 'today marriage', 'tomorrow', 'tomorrow monday', 'toys', 'toys help', 'trade', 'trade depressed', 'tragic', 'tragic cry', 'trung', 'trung cried', 'trusting', 'untill', 'valuable', 'valuable award', 'walk', 'wan', 'wan na', 'want', 'want see', 'we', 'we amuse', 'we amused', 'we happy', 'welcome', 'welcome speaker', 'well', 'well done', 'what', 'what hell', 'what interesting', 'what pity', 'what stupid', 'what tightwad', 'whenever', 'whenever i', 'who', 'who says', 'who think', 'win', 'winter', 'winter break', 'work', 'work art', 'working', 'worthless', 'you', 'you bastard', 'you bitch', 'you look', 'you lot', 'you re', 'you scoundrel', 'you valuable']\n"
     ]
    }
   ],
   "source": [
    "# Extract feature Bag_of_word\n",
    "tf_idf = TfidfVectorizer( ngram_range= (1,2) , token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "X = tf_idf.fit_transform(data_edited.reshape(149))\n",
    "print(len(tf_idf.get_feature_names()))\n",
    "print(tf_idf.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 648)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10,7,5),max_iter= 2000).fit(X, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hieu qua mo hinh dat : 100.0\n"
     ]
    }
   ],
   "source": [
    "predict = mlp.predict(X)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Hieu qua mo hinh dat :\", 100* accuracy_score(labels, predict.tolist() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "today happy smile \n"
     ]
    }
   ],
   "source": [
    "data1 = \"today i am very happy and smile\"\n",
    "words = word_tokenize(data1)\n",
    "string = \"\"\n",
    "for w in words:\n",
    "    if w not in stopWords:\n",
    "        string += w + \" \"\n",
    "print(string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy', 'happy smile', 'smile', 'today', 'today happy']\n"
     ]
    }
   ],
   "source": [
    "# Extract feature\n",
    "feature_test = np.zeros(len(tf_idf.get_feature_names()))\n",
    "\n",
    "tf_idf2 =  TfidfVectorizer( ngram_range= (1,2) , token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "X2 = tf_idf2.fit_transform([string])\n",
    "X_test = tf_idf2.get_feature_names()\n",
    "\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4472136 0.4472136 0.4472136 0.4472136 0.4472136]]\n"
     ]
    }
   ],
   "source": [
    "print(X2.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['happy']\n"
     ]
    }
   ],
   "source": [
    "feature_train = tf_idf.get_feature_names()\n",
    "for i in range(len(tf_idf.get_feature_names())):\n",
    "    for w in X_test:\n",
    "        if w == feature_train[i]:\n",
    "            feature_test[i] = 1\n",
    "predict_test = mlp.predict([feature_test])\n",
    "print(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature_of_test(data1):\n",
    "    words = word_tokenize(data1)\n",
    "    string = \"\"\n",
    "    for w in words:\n",
    "        if w not in stopWords:\n",
    "            string += w + \" \"\n",
    "    print(\"After discard : \",string)\n",
    "    feature_test = np.zeros(len(tf_idf.get_feature_names()))\n",
    "\n",
    "    tf_idf2 =  TfidfVectorizer( ngram_range= (1,2) , token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "    X2 = tf_idf2.fit_transform([string])\n",
    "    X_test = tf_idf2.get_feature_names()\n",
    "    feature_train = tf_idf.get_feature_names()\n",
    "    for i in range(len(tf_idf.get_feature_names())):\n",
    "        for w in X_test:\n",
    "            if w == feature_train[i]:\n",
    "                feature_test[i] = 1\n",
    "    return [feature_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After discard :  want go zoo \n",
      "['angry']\n"
     ]
    }
   ],
   "source": [
    "data1 = \"i kill you\"\n",
    "predict_test = mlp.predict(extract_feature_of_test(data1))\n",
    "print(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
